{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lytro Illum Demo \n",
    "\n",
    "This is a notebook recipe showing a sequence of steps necessary to read, calibrate and decompose a Lytro Illum photograph into so-called Sub-Aperture Images (SAIs) using **[PlenoptiCam](https://github.com/hahnec/plenopticam)**. SAIs correspond to perspective views in a light-field and can be thought of as viewpoint images captured by an array of cameras with consistent spacing. Because plenoptic cameras do not inherently feature this representation, the herein demonstrated decomposition is a crucial task in light-field imaging. \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>Note:</b> Due to the extensive memory requirements posed by the Illum files, this notebook yet only runs through on <a href=\"https://colab.research.google.com/github/hahnec/plenopticam/blob/develop/examples/04_illum_demo.ipynb\" title=\"GoogleColab\">GoogleColab</a>, which can be opened by clicking the badge below. <br>\n",
    "<br>\n",
    "<a href=\"https://colab.research.google.com/github/hahnec/plenopticam/blob/develop/examples/04_illum_demo.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package and import prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "print('Python v'+sys.version+'\\n')\n",
    "\n",
    "try:\n",
    "    import plenopticam as pcam\n",
    "except ImportError:\n",
    "    !pip install plenopticam>=0.6.4\n",
    "    import plenopticam as pcam\n",
    "print('PlenoptiCam v'+pcam.__version__+'\\n')\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except:\n",
    "    !pip install matplotlib --upgrade\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image data acquisition\n",
    "\n",
    "Available plenoptic photographs can be downloaded to the current folder ('./data') using the featured `DataDownloader` class, which is also used for extracting archived files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = pcam.misc.DataDownloader()\n",
    "loader.download_data(loader.host_eu_url, fp='./data')\n",
    "loader.extract_archive(archive_fn='./data/illum_test_data.zip', fname_list='lfr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration of *PlenoptiCam*\n",
    "\n",
    "Before running the light-field decomposition, file paths and basic calibration settings need to be set, using the `PlenopticamConfig` class as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate config object and set image file paths and options\n",
    "cfg = pcam.cfg.PlenopticamConfig()\n",
    "cfg.default_values()\n",
    "cfg.params[cfg.lfp_path] = './data/gradient_rose_close.lfr'\n",
    "cfg.params[cfg.cal_path] = './data/caldata-B5144402350.tar'\n",
    "cfg.params[cfg.opt_cali] = True\n",
    "cfg.params[cfg.ptc_leng] = 13\n",
    "\n",
    "# instantiate status object for progress\n",
    "sta = pcam.misc.PlenopticamStatus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a Lytro photograph\n",
    "\n",
    "Loading and decoding a raw Illum image is required on a binary level prior to calibration as the file's header payload contains metadata used in the file selection of a respective white calibration image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = pcam.lfp_reader.LfpReader(cfg, sta)\n",
    "reader.main()\n",
    "lfp_img = reader.lfp_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(lfp_img, cmap='gray', interpolation='none')\n",
    "plt.grid(False)\n",
    "plt.title('Raw Illum image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lytro's cameras come with a zoom lens whose setting affects centroid positions. Therefore it is important to choose a white image from the _caldata-*.zip_ archive that corresponds to the same optical setting the loaded Illum image was taken with. This task is covered by the `CaliFinder` class which is dedicated to Lytro cameras only and used hereafter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cal_finder = pcam.lfp_calibrator.CaliFinder(cfg, sta)\n",
    "ret = cal_finder.main()\n",
    "wht_img = cal_finder.wht_bay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(wht_img, cmap='gray', interpolation='none')\n",
    "plt.grid(False)\n",
    "plt.title('Raw white calibration image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the image data is read and stored in the `lfp_img` and `wht_img` variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Micro image calibration\n",
    "\n",
    "Once the white image is present, localization of micro image centroids $\\mathbf{c}_{j,h}$ is conducted with the `LfpCalibrator` class at an abstract level. Results can be inspected in the plots below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_obj = pcam.lfp_calibrator.LfpCalibrator(wht_img, cfg, sta)\n",
    "ret = cal_obj.main()\n",
    "cfg = cal_obj.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = cfg.load_cal_data()\n",
    "y_coords = [row[0] for row in cfg.calibs[cfg.mic_list]]\n",
    "x_coords = [row[1] for row in cfg.calibs[cfg.mic_list]]\n",
    "\n",
    "s = 3\n",
    "h, w, c = wht_img.shape if len(wht_img.shape) == 3 else wht_img.shape + (1,)\n",
    "hp, wp = 80, 80\n",
    "fig, axs = plt.subplots(s, s, facecolor='w', edgecolor='k')\n",
    "\n",
    "for i in range(s):\n",
    "    for j in range(s):\n",
    "        # plot cropped image part\n",
    "        k = i * (h // s) + (h // s) // 2 - hp // 2\n",
    "        l = j * (w // s) + (w // s) // 2 - wp // 2\n",
    "        axs[i, j].imshow(wht_img[k:k+hp, l:l+wp, ...], cmap='gray')\n",
    "\n",
    "        # plot centroids in cropped area\n",
    "        coords_crop = [(y, x) for y, x in zip(y_coords, x_coords) \n",
    "                       if k <= y <= k+hp-.5 and l <= x <= l+wp-.5]\n",
    "        y_centroids = [row[0] - k for row in coords_crop]\n",
    "        x_centroids = [row[1] - l for row in coords_crop]\n",
    "        axs[i, j].plot(x_centroids, y_centroids, 'bx', \n",
    "                       markersize=4, label=r'Centroids $\\mathbf{c}_{j,h}$')\n",
    "        axs[i, j].grid(False)\n",
    "        axs[i, j].tick_params(top=False, bottom=True, left=True, right=False,\n",
    "                              labelleft=True, labelbottom=True)\n",
    "        axs[i, j].set_yticks([sum(t) for t in zip(list(range(0, hp+1, hp//2)), [0,0,0])])\n",
    "        axs[i, j].set_xticks(list(range(0, wp+1, wp//2)))\n",
    "        axs[i, j].set_yticklabels([str(k), str(k+hp//2), str(k+hp)])\n",
    "        axs[i, j].set_xticklabels([str(l), str(l+wp//2), str(l+wp)])\n",
    "\n",
    "\n",
    "# set common labels\n",
    "fig.text(0.5, -0.05, 'Horizontal dimension [px]', ha='center', va='center', fontsize=14)\n",
    "fig.text(-0.01, 0.5, 'Vertical dimension [px]', ha='center', va='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(3, 3.85), fancybox=True, shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Micro image alignment\n",
    "\n",
    "With the centroids estimated, the original `lfp_img` is rectified by means of the `LfpAligner` class such that Lytro's hexagonally ordered micro images are rearranged to a rectangular grid exposing consistent resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = cfg.load_cal_data()\n",
    "aligner = pcam.lfp_aligner.LfpAligner(lfp_img, cfg, sta, wht_img)\n",
    "ret = aligner.main()\n",
    "lfp_img_align = aligner.lfp_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, basename\n",
    "import pickle\n",
    "\n",
    "with open(join(cfg.exp_path, 'lfp_img_align.pkl'), 'rb') as f:\n",
    "    lfp_img_align = pickle.load(f)\n",
    "    \n",
    "plt.figure()\n",
    "plt.imshow(lfp_img_align/lfp_img_align.max(), interpolation='none')\n",
    "plt.grid(False)\n",
    "plt.title('Aligned Illum image')\n",
    "plt.show()\n",
    "\n",
    "try:\n",
    "    from plenopticam.lfp_reader import LfpDecoder\n",
    "    # try to load json file (if present)\n",
    "    json_dict = cfg.load_json(cfg.exp_path, basename(cfg.exp_path)+'.json')\n",
    "    cfg.lfpimg = LfpDecoder.filter_lfp_json(json_dict, cfg.lfpimg)\n",
    "except FileNotFoundError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-Aperture Image (SAI) extraction\n",
    "\n",
    "Rendering perspective views, known as SAIs, from an aligned light-field image `lfp_img_align` is accomplished by a `LfpExtractor` object. The resulting `vp_img_arr` is displayed in various ways further below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = pcam.lfp_extractor.LfpExtractor(lfp_img_align, cfg, sta)\n",
    "ret = extractor.main()\n",
    "vp_img_arr = extractor.vp_img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_obj = pcam.lfp_extractor.LfpViewpoints(vp_img_arr=vp_img_arr)\n",
    "vp_view = view_obj.central_view\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(vp_view/vp_view.max(), interpolation='none')\n",
    "plt.grid(False)\n",
    "plt.title('Central sub-aperture image view')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_obj = pcam.lfp_extractor.LfpViewpoints(vp_img_arr=vp_img_arr)\n",
    "vp_stack = view_obj.views_stacked_img\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(vp_stack/vp_stack.max(), interpolation='none')\n",
    "plt.grid(False)\n",
    "plt.title('All sub-aperture images view')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_obj = pcam.lfp_extractor.LfpViewpoints(vp_img_arr=vp_img_arr)\n",
    "vp_arr = view_obj.reorder_vp_arr(pattern='circle', lf_radius=3)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('View animation')\n",
    "l = ax.imshow(vp_arr[0])\n",
    "animate = lambda i: l.set_data(vp_arr[i])\n",
    "anim = animation.FuncAnimation(fig, animate, frames=len(vp_arr))\n",
    "plt.close() # get rid of initial figure\n",
    "\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational change of focus\n",
    "\n",
    "The light-field's well known synthetic focus capability is managed by the `LfpRefocuser` class with exemplary parameter setting $a=[-1,2]$ in the `cfg.params` dictionary and key `cfg.ran_refo` controling the refocused range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use non-gamma corrected viewpoint array\n",
    "vp_img_linear = extractor.vp_img_linear\n",
    "# set refocus range $a$\n",
    "cfg.params[cfg.ran_refo] = [-1, 2]\n",
    "# skip status messages\n",
    "cfg.params[cfg.opt_prnt] = False\n",
    "\n",
    "refocuser = pcam.lfp_refocuser.LfpRefocuser(vp_img_arr=vp_img_linear, cfg=cfg)\n",
    "refocuser.main()\n",
    "refo_stack = refocuser.refo_stack\n",
    "\n",
    "fig, ax = plt.figure(figsize=(5, 3)), plt.gca()\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "plt.close() # get rid of initial figure\n",
    "ax.set_title('Refocusing animation')\n",
    "ax.tick_params(top=False, bottom=False, left=False, right=False, labelleft=False, labelbottom=False)\n",
    "l = ax.imshow(refo_stack[0])\n",
    "animate = lambda i: l.set_data(refo_stack[i])\n",
    "anim = animation.FuncAnimation(fig, animate, frames=len(refo_stack), interval=1000)\n",
    "\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth map extraction\n",
    "\n",
    "Depth inference from light-fields is a capability *PlenoptiCam* offers by means of the `LfpDepth` class using the parameter key `cfg.opt_dpth` in the `cfg.params` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute and write depth data from epipolar analysis\n",
    "if cfg.params[cfg.opt_dpth]:\n",
    "    obj = pcam.lfp_extractor.LfpDepth(vp_img_arr=vp_img_arr, cfg=cfg, sta=sta)\n",
    "    obj.main()\n",
    "    depth_map = obj.depth_map\n",
    "\n",
    "# plot depth map in 2-D\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Depth map')\n",
    "ax.imshow(depth_map, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# plot depth map in 3-D\n",
    "fig, ax = plt.figure(figsize=(5, 5)), plt.axes(projection='3d')\n",
    "ax.set_facecolor('#ffffff') #148ec8\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "ax = obj.plot_point_cloud(rgb_img=vp_view, down_scale=2, ax=ax)\n",
    "plt.close() # get rid of initial figure\n",
    "animate = lambda i: ax.view_init(60, 60+i*20)\n",
    "anim = animation.FuncAnimation(fig, animate, frames=18, interval=100, repeat=True)\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim.save('depth_anim.gif', writer='imagemagick', fps=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
